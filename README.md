# ğŸš€ Customer Churn Prediction - Full Stack ML Application

A production-ready machine learning application for predicting customer churn with a FastAPI backend and Streamlit frontend.

## ğŸ—ï¸ Architecture

```
Frontend (Streamlit) â†â†’ REST API â†â†’ Backend (FastAPI)
     â”‚                                    â”‚
   User Interface              ML Models + Analytics
```

## âœ¨ Features

### ğŸ”® Predictions Page
- Real-time churn predictions
- Multiple ML models (Random Forest, XGBoost, Gradient Boosting, Logistic Regression)
- Interactive feature inputs with proper validation
- Confidence scoring and probability visualization
- Customizable prediction threshold

### ğŸ“ˆ Insights Page
- Feature importance analysis
- Model performance comparison
- Interactive charts and visualizations
- Model interpretability tools

## ğŸš€ Quick Start

### Backend (FastAPI)
```bash
cd backend
pip install -r requirements.txt
uvicorn main:app --reload
```
API will be available at: http://localhost:8000
API Documentation: http://localhost:8000/docs

### Frontend (Streamlit)
```bash
cd frontend
pip install -r requirements.txt
streamlit run app.py
```
App will be available at: http://localhost:8501

## ğŸ“ Project Structure

```
churn-prediction/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py              # FastAPI application
â”‚   â”œâ”€â”€ models/              # Trained ML models (.pkl files)
â”‚   â”œâ”€â”€ x_test.csv          # Sample data for feature ranges
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ app.py              # Streamlit application
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ data/                   # Training data (optional)
â””â”€â”€ README.md
```

## ğŸ”§ API Endpoints

- `GET /` - API status and info
- `GET /health` - Health check
- `GET /models` - Available models
- `GET /feature-stats` - Feature statistics
- `POST /predict/{model_name}` - Make predictions
- `GET /feature-importance/{model_name}` - Get feature importance

## ğŸš€ Optimized Deployment

### Performance Optimizations:
- **Memory efficient**: Models loaded once, cached predictions
- **Fast startup**: Optimized Docker images with multi-stage builds
- **Compressed responses**: GZip middleware enabled
- **Caching**: LRU cache for feature importance, API responses
- **Input validation**: Pydantic models with constraints
- **Resource limits**: Docker memory limits for cost efficiency

### Deployment Options:

**Option 1: Railway (Recommended)**
1. Fork this repository
2. Connect to Railway
3. Deploy backend: `railway up` (uses railway.json)
4. Deploy frontend: Set `API_BASE_URL` environment variable

**Option 2: Docker Compose (Local/VPS)**
```bash
docker-compose up --build
```

**Option 3: Separate Services**
- Backend: Railway/Render/Fly.io
- Frontend: Streamlit Cloud

### Environment Variables:
- `API_BASE_URL`: Backend URL (for frontend)
- `ENVIRONMENT`: Set to "production" to disable docs
- `PORT`: Port for Railway deployment (auto-set)

## ğŸ› ï¸ Technologies Used

**Backend:**
- FastAPI - Modern, fast web framework
- Pydantic - Data validation
- Scikit-learn - ML models
- Pandas - Data manipulation
- Uvicorn - ASGI server

**Frontend:**
- Streamlit - Web app framework
- Plotly - Interactive visualizations
- Requests - HTTP client

## ğŸ“Š Models Included

1. **Random Forest** - Ensemble method, good for feature importance
2. **XGBoost** - Gradient boosting, high performance
3. **Gradient Boosting** - Sequential ensemble method
4. **Logistic Regression** - Linear model, interpretable

## ğŸ¯ Features for Prediction

- Price
- Freight Value
- Payment Installments
- Delivery Difference (days)
- Reviewed Days
- Customer State (encoded)
- Product Category (encoded)
- Payment Type (encoded)

## ğŸ”® Future Enhancements

- [ ] Model retraining pipeline
- [ ] A/B testing framework
- [ ] Real-time monitoring
- [ ] User authentication
- [ ] Model versioning
- [ ] Batch predictions
- [ ] Data drift detection

## ğŸ“ˆ Performance

- **API Response Time**: < 100ms
- **Model Loading**: On startup (faster predictions)
- **Concurrent Users**: Supports multiple simultaneous requests
- **Scalability**: Horizontal scaling ready

## ğŸ¤ Contributing

1. Fork the repository
2. Create feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open Pull Request

## ğŸ“„ License

This project is licensed under the MIT License.

## ğŸ™‹â€â™‚ï¸ Support

For questions or issues, please open a GitHub issue or contact [your-email].

---

**Built with â¤ï¸ for the ML community**